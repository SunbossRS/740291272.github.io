---
layout: post
title: Winodws平板电脑安装Ubuntu
category: USE
tags: 日志 blog 博文
---

Nakloidが歌声を出力するまで

## 基本的な考え方

Nakloidは、[[背景]]で説明したとおり、TD-PSOLA法がベースです。ここで重要なのが、TD-PSOLA法の中間生成物である単位波形。Nakloidでは単位波形を編集したり、うまく並び替えたりしたりすることで、歌声DBに登録された音声波形を歌声へと変えています。これにより歌声DBに登録された音声波形の特徴をできる限り残したまま、自然な歌声合成を行うことを目標とします。副次的な効果として、時間領域でのみ波形編集を行うことにより、軽量・高速（当社比）に歌声合成を行えます。

この「単位波形指向合成」を行うため、楽譜情報からまず曲全体の周波数（F0）リストを生成しています。そこから出力用のピッチマークリストを生成、単位波形を並べているのです。これにより音符と音符のオーバーラップ部分の位相が揃うので、VCV単位での合成においてもなめらかなF0変化を実現しています。

### 音高変換

音高変換（基本周波数の変更）こそTD-PSOLA法の真骨頂。周波数領域で波形を編集したものよりも高品質（≒自然で歪みのない）な合成音声を出力することができます。

それと地味に重要なのが、単位波形を再配置する際の時間軸の調整。ただ間隔を調整するだけでは子音・母音や声量・声質の変化する位置も移動してしまうので、Nakloidは、単位波形を補完するTDI-PSOLA法を採用しています。考案者の論文はフランス語だったりするので、知りたい方は後発の[この論文](http://quod.lib.umich.edu/cgi/p/pod/dod-idx?c=icmc;idno=bbp2372.2000.214)あたりをどうぞ。

ただし、TD-PSOLA法も万能ではなく、基本周波数を一定以上変更すると音質の悪化が耳につくようになります。歌声合成は話声合成よりも基本周波数の変化が大きいため、対策を考えてやる必要があります。

[望月氏の論文](http://hdl.handle.net/2065/5312)や[田中氏の論文](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=596095)では周波数領域で単位波形の低域スペクトルを補正していますが、コードを書くのがメドいもとい時間領域のみの編集でなんとかするため、Nakloidでは下記のように窓関数の改善で対処しています。

#### 窓関数の拡張

一つは、基本周期の２倍長以上の長さで単位波形を切り出す方法。主に初期のNakloidで採用していました。TD-PSOLA法は単位波形をインパルス応答波形として用いているため、何も考えず窓関数を拡張すると悲惨なことに。そこで、直感的にうまくいきそうな、Sinc関数類似でうまくTD-PSOLA法に適合しそうな関数として、画像の拡大縮小で用いられる[Lanczos関数](http://en.wikipedia.org/wiki/Lanczos_resampling)を採用。以下はTD-PSOLA法で通常用いられるHann窓と、Nakloidの採用したLanczos窓の比較です。

![Hann窓とLanczos窓](https://github.com/acknak/Nakloid/wiki/images/2-1.png)

……と、上手くいっていそうなことを書きましたが、効果は気休め程度。研究室時代、15名ほどを対象に行ったブラインドテストでは、平均値こそ確かに既存手法を上回っているものの、統計的に有意かと言われれば……。まぁ、暇な人は比較実験してみて下さい。

#### 目標周波数に応じた窓関数の変形

前掲の窓関数の拡張の効果が薄いため、新たに編み出した方法が、目標とするピッチマーク位置（ピッチ幅）により窓関数を変形する方法。具体的には、下記の式のαを、半値半窓が出力後のピッチの半分になるよう設定してやる変形を施しています。[解説動画](http://nico.ms/sm17093726)の2:52～も合わせてご参照下さい。

![変形Hann窓](https://github.com/acknak/Nakloid/wiki/images/2-3.png)

一応、前掲の「窓関数の拡張」と組み合わせられるはずですが、そもそもこの方法が上手くいく理由がよくわかっていないこともあり保留中です。

### 音長変換

次は発声時間の変更について。問題となるのは、歌声DBに登録された波形よりも長い時間の発声が必要になった場合（音声DBに十分長い時間の音声を登録しておけばいいのでは？という話でもありますが）。Nakloidでは音声波形が自分自身にフェードし続けることで無限の発声時間を実現しています。これは誰もが思いつく有名な技術ですが、名称がわからなかったのでとりあえず「自己フェード」と呼んでいます。誰か正しい呼び方を教えて下さい。

![自己フェード概念図](https://github.com/acknak/Nakloid/wiki/images/2-2.png)

この手法の欠点は、フェード元とフェード先で位相が揃うとは限らないことにより、フェードの中間部分で音声が二重に聴こえてしまうところ。そこでNakloidでは、「単位波形指向合成」の理念に則り、単位波形毎に自己フェードを施して位相を揃えています。例えば

a,b,c,d,e,f,g,h,i,j

という順番で単位波形があったとして、これを伸ばすと

a,b,c,d,e,f,(0.8g+0.2b),(0.6h+0.4c),(0.4i+0.6d),(0.2j+0.8e),f,(0.8g+0.2b),(0.6h+0.4c),(0.4i+0.6d),(0.2j+0.8e),f,...

となります。なお、Nakloidでは、2つの単位波形を合成する際にRMS（二乗平均平方根）レベルを揃えてやることでノーマライズしています。

### 歌声特性付与

[[背景]]のページでも紹介しましたが、歌声特有の性質として基本周波数の変化と"Singers' formant"と呼ばれる周波数領域の特徴があります。Nakloidの場合、元となる音声波形は「歌声」としてDBに登録されたものであるとして考慮していません。したがって、歌声特性の付与としては、基本周波数の変化（ビブラート、プレパレーション、オーバーシュート、微細変動）を施すに留めています。

## 合成の流れ

1. 音符情報を取得
2. 音符情報から曲全体のF0配列を作成
3. F0配列にプレパレーション、オーバーシュート等を付与
4. 歌声DBから歌詞と一致する発音の音声波形を取得
5. 音声波形の音高を音符情報に合わせて変換
6. 音声波形の音長を音符情報に合わせて変換
7. 歌声DBの情報から合成音声の出力位置を決定・重畳加算
8. 1.へ戻る
